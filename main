import LoadData
import DisplayData
import pandas as pd
import numpy as np
import CleanData
import TrainData
from sklearn import datasets

#test display data

'''
diabetes = datasets.load_iris()
data=LoadData.dataset2df(diabetes)
DisplayData.showStatistic(data)
DisplayData.showBins(data)
DisplayData.showStd(data)
DisplayData.showPlot(data)
DisplayData.showSubPlot(data)
DisplayData.showCorrMap(data)
DisplayData.showSPLOM_G(data)
'''
#datasets=datasets.load_iris()
#data=LoadData.dataset2df(datasets)
#print(data.describe())
#print(data.loc[:10])
#a=CleanData.EnumData(data.loc[:10],"sepal length (cm)",cut_ranges=[3,4.8,6],right=True,enumnames=["a","b"])
#print(a)
#data1=LoadData.getFormatChanArch('192.168.44.165',23,['BIBPM:R1OBPM02:XPOS'],'05/10/2018 14:15:00','05/10/2018 14:16:00','outer','linear',None,0)
#print(data1)
#data2=LoadData.getFormatChanArch('192.168.44.165',27,['BIBPM:R1OBPM02:STAT'],'05/10/2018 14:15:00','05/10/2018 14:16:00','outer',None,'pad',0,False)
#print(data2)
#data3=LoadData.mergeDF(data2,data1,'outer')
#print(data3)

#test load data function
'''
bpmsnames=LoadData.getTXTpv('E:','bpms.txt')
data_live=LoadData.generate_live_data(2,['qiaoysHost:ai1','qiaoysHost:ai2'])
data_raw_char=LoadData.getChanArch('192.168.44.165',16,['BPR:LIFE','R3O:BI:DCCT:CUR'],'04/28/2018 00:00:00','04/28/2018 00:00:30',0)
LoadData.getKey('192.168.44.165',['BIBPM:R1OBPM02:XPOS','BIBPM:R1OBPM03:XPOS','BIBPM:R1OBPM04:XPOS','BIBPM:R1OBPM05:XPOS','BIBPM:R1OBPM06:XPOS','BIBPM:R1OBPM07:XPOS','BIBPM:R1OBPM08:XPOS'])
data_format_char=LoadData.getFormatChanArch('192.168.44.165',23,['BIBPM:R1OBPM02:XPOS','BIBPM:R1OBPM03:XPOS','BIBPM:R1OBPM04:XPOS','BIBPM:R1OBPM05:XPOS','BIBPM:R1OBPM06:XPOS','BIBPM:R1OBPM07:XPOS','BIBPM:R1OBPM08:XPOS'],'05/10/2018 08:35:00','05/10/2018 08:38:00','outer',linear,None,0)
data_arapp=LoadData.getArchAppl('ss',['BPR:LIFE','R3O:BI:DCCT:CUR','R4O:BI:DCCT:CUR'],'04/28/2018 00:00:00','04/28/2018 00:00:30')
data=LoadData.getLocalFile('E:','test.csv',0)
'''
#key=LoadData.getKey(ipaddr='192.168.44.165',pvnames=['BER:PMO','R3O:BI:DCCT:CUR'])
server,engine=LoadData.connectChanArch(ipaddr='192.168.44.165')
pvnames=['BIBPM:R1IBPM03:XPOS','BIBPM:R1OBPM02:XPOS','L:BI:BPM1:softao:y']
start='2018/10/25 08:20:00'
end='2018/10/28 08:40:00'
#key=LoadData.getKeyWithTime(server,engine,pvnames=['BER:PMO','R3O:BI:DCCT:CUR','L:BI:BPM1:softao:y'],start='2018/10/13 08:35:00',end='2018/10/13 08:36:00')
#print(key)
data=LoadData.getFormatChanArch(server,engine,pvnames,start,end,merge_type='inner')
print(data)
#data=LoadData.getFormatChanArch(ipaddr='192.168.44.165',key=15,pvnames=['BER:LIFE'],start='2018/10/24 08:35:00',end='2018/10/24 08:36:00',merge_type='outer',interpolate_type='linear',fillna_type=None,how=0)

#data1=LoadData.getFormatChanArch(ipaddr='192.168.44.165',key=15,pvnames=['MP:EALLBEAM'],start='2018/10/24 08:35:00',end='2018/10/24 08:36:00',merge_type='outer',interpolate_type='linear',fillna_type=None,how=0)
#print(data1)
#data2=LoadData.getFormatChanArch(ipaddr='192.168.44.165',key=15,pvnames=['BER:LIFE','MP:EALLBEAM'],start='2018/10/24 08:35:00',end='2018/10/24 08:36:00',merge_type='outer',interpolate_type='linear',fillna_type=None,how=0)
#print(data2)

#test merge df
'''
data1=LoadData.getFormatChanArch('192.168.44.165',23,['BIBPM:R1OBPM02:XPOS'],'05/10/2018 14:15:00','05/10/2018 14:16:00','outer','linear',None,0)
data2=LoadData.getFormatChanArch('192.168.44.165',27,['BIBPM:R1OBPM02:STAT'],'05/10/2018 10:15:00','05/10/2018 14:16:00','1',None,'pad',0)
data3=LoadData.mergeDF(data2,data1,'outer')
'''
#test get channel archiver engine keys
'''
a=LoadData.getChanArchEngineKey('192.168.44.165','BESII:180927-now')
print(a)
'''

'''
LoadData.getKey('192.168.44.165',['L:BI:BPM1:softao:x','L:BI:BPM1:softao:y'])
'''
#test clean data
'''
diabetes = datasets.load_iris()
data=LoadData.dataset2df(diabetes)
CleanData.NormData(data,norm_type="min-max")
CleanData.EnumData(data,'BPR:LIFE',[1,2.76,2.78,3],True,["small","Medium","big"])
newdata=data[data['BESIII:LUMAVG']<0.52]
'''

#test LinearRegression
'''
data = pd.read_csv('E:\CCPP\ccpp.csv')
X_train, X_test, y_train, y_test =TrainData.split_data(data,'PE')
pred,score=TrainData.MLLinearRegression( X_train, X_test, y_train, y_test)
DisplayData.subplot_predict(y_test, pred,title='score: %f' % score)

'''

#test GaussianNB
'''
iris = datasets.load_iris()
data=LoadData.dataset2df(iris)
X_train, X_test, y_train, y_test =TrainData.split_data(data,'target')
pred,score=TrainData.MLGaussianNB_testmodel( X_train, X_test, y_train, y_test)
DisplayData.subplot_predict(y_test, pred,title='score: %f' % score)
#testdata=np.array([[ 5.1,3.5,1.4,0.2],[4,4,2,1.8]])
#TrainData.MLGaussianNB(data,"target",testdata)
'''


#test Decision Trees
'''
iris = datasets.load_iris()
data=LoadData.dataset2df(iris)
#testdata=np.array([[ 5.1,3.5,1.4,0.2],[4,4,2,1.8]])
#TrainData.MLDecisionTrees(data,"target",testdata)
X_train, X_test, y_train, y_test =TrainData.split_data(data,'target')
pred,score=TrainData.MLDecisionTrees_testmodel( X_train, X_test, y_train, y_test)
DisplayData.subplot_predict(y_test, pred,title='score: %f' % score)
'''


#test PolynimialRegression
'''
data = pd.read_csv('E:\CCPP\ccpp.csv')
X_train, X_test, y_train, y_test =TrainData.split_data(data,'PE')
pred,score=TrainData.MLPolynomialRegression( X_train, X_test, y_train, y_test,4)
DisplayData.plot_predict(y_test, pred,title='score: %f' % score)
'''


#test KNN
'''
data=LoadData.getFormatChanArch('192.168.44.165',16,['BESIII:LUMAVG','R3O:BI:DCCT:CUR','R4O:BI:DCCT:CUR'],'05/10/2018 08:35:00','05/10/2018 08:38:00','outer','linear',None,0)
X_train, X_test, y_train, y_test=TrainData.split_data(data,'BESIII:LUMAVG')
pred,score=TrainData.MLKNN_Regression(X_train, X_test, y_train, y_test,'shuffle')
DisplayData.subplot_predict(y_test, pred,title='score: %f' % score)
'''

'''
iris = datasets.load_iris()
data=LoadData.dataset2df(iris)
X_train, X_test, y_train, y_test=TrainData.split_data(data,"target")
y_pred,score=TrainData.MLKNN_Classification(X_train, X_test, y_train, y_test,k=5,weights="distance")
DisplayData.plot_predict(y_test,y_pred,title='score: %f' % score)
'''

#test Logistic Regression
'''
diabetes = datasets.load_iris()
data=LoadData.dataset2df(diabetes)
X_train, X_test, y_train, y_test=TrainData.split_data(data,"target")
TrainData.test_LogisticRegression_C(X_train,X_test,y_train,y_test)
pred,score=TrainData.MLLogisticRegression_testmodel(X_train,X_test,y_train,y_test,c=1.149)
DisplayData.subplot_predict(y_test, pred,title='score: %f' % score)
'''


'''
diabetes = datasets.load_iris()
data=LoadData.dataset2df(diabetes)
X_train, X_test, y_train, y_test=TrainData.split_data(data,"target")
TrainData.MLLogisticRegression_testmodel(X_train,X_test,y_train,y_test)
testdata=np.array([[ 5.1,3.5,1.4,0.2],[4,4,2,1.8]])
TrainData.MLLogisticRegression(diabetes.data,diabetes.target,testdata)

'''


# test DBSCAN
'''
iris = datasets.load_iris()
data=LoadData.dataset2df(iris)
target_pv="target"
TrainData.MLDBSCAN(data,target_pv)
'''

#test MLKMeans 2 features better for plot result
'''
iris = datasets.load_iris()
data=LoadData.dataset2df(iris)
feature_pv1='sepal length (cm)'
feature_pv2="sepal width (cm)"
print(data.columns.tolist())
TrainData.MLKMeans(data,feature_pv1,feature_pv2)
'''


#test MLPClassifier
'''
iris = datasets.load_iris()
data=LoadData.dataset2df(iris)
X_train, X_test, y_train, y_test = TrainData.train_test_split(data.iloc[:,0:3],data['target'], test_size=0.3, random_state=42)
y_pred,score=TrainData.MLMLPClassifier(X_train, X_test, y_train, y_test)
DisplayData.plot_predict(y_test,y_pred,title='score: %f' % score)
'''


#test anolog data
'''
data=LoadData.getAnalogData()
data_X=data[['X_end','X_bpm1','X_bpm2']]
X_train, X_test, y_train, y_test=TrainData.split_data(data_X,"X_end")
TrainData.MLLinearRegression(X_train, X_test, y_train, y_test)
'''



